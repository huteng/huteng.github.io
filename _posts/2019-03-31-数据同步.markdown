---
layout: post
category: "read"
title:  "数据同步"
tags: [同步]
---

## 常见的两种同步方式

### 全量对比

对比就是客户端请求服务端所有关键数据，跟本地已有的数据进行对比，筛选出增删改的数据进行更新。

用对比方法的好处是服务端什么都不用做，坏处是客户端逻辑复杂，耗网络流量。在这种方案里，数据的新增和删除很容易判断，根据客户端数据的 id 列表和服务端数据的 id 列表进行对比就行，若要判断哪个数据有修改则比较麻烦，需要取回数据进行对比，如果从服务端拉回所有对所有数据进行对比会很耗网络流量，有一个优化方式，就是对每个数据的修改进行标记。若服务端因为某些原因无法给每个数据保存一个版本标记，可以实时计算，在客户端和服务端约定一个算法，把所有可变参数拿出来，通过特定算法hash出一个值，对比这个hash值判断是否需要更新。

组织架构最初版本就是采用类似的思路。

![全量组织架构](../img/全量同步.png)

### 增量日志

日志指服务端记录数据的每一次增删改，用一个类似版本号的sync-key标记这次修改，客户端通过一个旧的sync-key向服务端请求，服务端返回这个sync-key与最新sync-key之间所有的修改给客户端，完成增量更新。

这个sync-key在服务端的实现上可以是时间，也可以是一个自增的seq或id，sync-key之间有顺序关系就行。在一个数据集里，每次数据有更新，就新增一个sycn-key，并记录这次更新。图示这个过程：

![同步seq示意图](../img/同步seq示意图.png)

一是时间长了服务端保存数据量过大。可以通过限制记录的条数解决，超过限制就删除最旧的记录。这样做会出现一个问题，若客户端带着在服务端已被删除的sync-key上来请求，该如何处理？一般做法是返回一个错误给客户端，让客户端重新拉取所有数据。

二是若客户端sync-key过旧，增量数据可能过大。客户端数据太老，有太多数据需要更新，若一次性返回所有增量数据，这个请求可能会很大，请求时间太长，成功率也会很低。解决方式是分多次请求，客户端和服务端可以约定一个字段作为阀值，服务端每次返回的增量数据量不超过这个阀值，若总数据超过这个阀值，则分多次请求，通过每次请求返回的sync-key定位下次请求该返回哪些数据。

企业微信组织架构后来就是在此基础上做的优化。并且融合了架构隐藏等策略。

## 企业微信组织架构

企业微信组织架构主要有两个特点：数据量大，隐藏规则复杂。因此单一的全量对比或增量日志的方案，在此都不存在一定的问题。在经过多个版本迭代后，最新的组织架构协议如下：

### 协议

企业微信中，同步方案核心思想为:

> **服务端下发增量节点，且支持传阈值来分片拉取增量节点，若服务端计算不出客户端的差量，下发全量节点由客户端来对比差异**。

1. 客户端传入本地版本号，拉取变更节点。若后台算不出增量节点，则下发全量节点，由客户端对比需要增加或删除哪些节点。
2. 客户端拉取变更节点的具体信息。
3. 客户端判断架构同步是否完成，若尚未完成，重复步骤1。

![image-20190108122720499.png](../img/image-20190108122720499.png)

### 存储

总共分为三张表：

1. User表。存储成员具体信息。
2. MYHEAD表。存储成员在部门下的关系。比如成员在部门下的排序值，身份等。
3. Department表。存储部门信息，部门信息上有parent_department_id。

![1490005786_77_w989_h546](../img/1490005786_77_w989_h546.png)

### 缓存

1. 全量成员vid。
   * 数据结构为 `std::set`，存储了全企业的成员vid。
   * 用法：用于上层同步判断哪些人在组织架构。
   * 更新时机：启动初始化，当组织架构有变更时更新。
2. 全量架构树。
   * 数据结构为`std::map`，key为 `std::pair<DepartmentId, UserId>`，value为成员在部门下的信息（job、displayorder，attr等）
   * 用法：在组织架构同步过程中加速比较出增删改、计算组织架构人数等。
   * 更新时机：组织架构开始时初始化、随组织架构变更更新。

## 同步策略

### 数据一致性

如果要做到数据一致性，特别需要注意版本号的存储：

1. 版本号要在所有数据处理完成后存入，数据和版本号放在同一个 DB。
2. **谨慎使用内存版本号**。若当前同步拉取到的DB版本号和数据存失败了，但是更新了内存版本号，此时用内存版本号去同步再存入，会造成数据丢失。

### 同步串行防重入

![顺序1](../img/顺序1.png)

![顺序2](../img/顺序2.png)

该图中，同步的途中插入了另外一次同步，很容易造成问题：

1. 输出结果不稳定。若两次同步几乎同时开始，但因为存在网络波动等情况，返回结果可能不同，给调试造成极大的困扰。
2. 中间状态错乱。若同步中处理服务端返回的结果会依赖于请求同步时的某个中间状态，而新的同步发起时又会重置这个状态，很可能会引起匪夷所思的异常。
3. 时序错乱。整个同步流程应该是原子的，若中间插入了其他同步的流程会造成整个同步流程时序混乱，引发异常。

具体做法，同步串行化：

1. bool 值的方式。
2. PromiseSerialExecutor。

###异常处理

1. 组织架构损坏监控。DB 损坏后通知上层刷新。

2. 同步检测：若没取到根目录，且组织架构没被隐藏，版本号不为空。则强制请求全量更新

   ```c++
   // 每次同步完组织架构后、若发现无变更，则检测一次。
   void DepartmentServiceImpl::CheckArchTreeValid() {
       if (department_data_.incre_arch_version().length() &&
           department_root_list_.size() == 0 &&
           repair_arch_db_count_ < 1) {
           // 如果版本号不为空，且没有根节点，则视为组织架构异常
           // 单个生命周期内最多做1次
           GetRootDepartments(base::BindLambda(base::AsWeakPtr(this), [=](LogicErrorCode, const model::DepartmentList& department_list) {
               if (department_list.size() == 0) {
                   repair_arch_db_count_++;
                   ForceSyncAllDepartment();
               }
           }));
       }
   }
   ```

3. 对后台返回的异常数据的兼容。过滤后台返回的无效数据，并且防止雪崩。在线上版本，尽量避免后台返回了异常数据导致的客户端数据异常。

## 逻辑优化 

逻辑优化是针对代码层面的优化，需要在迭代过程中不断完善整理。

#### 数据结构：小心 vector 的内存使用

* 类似于vector、string在内存重分配时，流程为：

  1. 分配一块当前内存数倍的新内存。在大多数容器的实现中，内存是以2的倍数增长。
  2. 把容器中的所有元素从旧的内存拷贝到新的内存。
  3. 析构掉旧内存的对象。
  4. 释放旧内存。
* 内存重分配的过程中，所有的迭代器，引用，指针都会失效。
* 合理利用 `reserve` 提前申请足够的内存，可以减少内存的重新分配
* 当 vector 元素减少时，应该将申请的额外内存给释放掉。使用 `shrink_to_fit`。

#### 数据库部分：先插入数据、再建立索引

减少了插入时，索引的重建，实际上性能提升30%。但是需要注意的是，如果索引建立前，上层来取数据会非常慢。

#### 数据库部分：批量操作 > 单条操作

1. 将批量插入放入单个事务来做。由于企业微信本身就有自动事务管理，这条在企业微信内部优化不大。
2. 减少 sqlite 执行次数，降低编译语句的损耗。但是要注意 SQLite 语句有最大长度限制。

```c++
// batch_spliter.h
template<typename ListType>
void BatchSplit(const ListType &list, 
				int batch_length,
				const std::function<void(const ListType&)>& split_callback) {
	int batch_number = static_cast<int>(list.size() / batch_length);

	for (int i = 0; i <= batch_number; i++) {
		auto begin = list.begin() + (i * batch_length);
		auto end = (i == batch_number) ?
			list.end() : list.begin() + ((i + 1) * batch_length);
		if (begin != end) {
			ListType batch(begin, end);
			split_callback(batch);
		}
	}
}
```

## 策略优化

业务相关，因地制宜的进行优化，每个业务层面都会有优化空间。而且从实际效果来看，从策略上做优化，往往效果是比较好的。

### 精简 UserInfo

区分胖瘦数据，支持仅下发精简字段。需要注意的是，客户端处理UserInfo时，需要将数据做 Merge 操作。具体做法是在组织架构更新时，若识别到是超大型企业，则在架构更新时仅下发精简数据，完整数据需要从 GetUserInfo 拉取。

并且在组织架构更新层面讲 UserInfo 和具体字段更新的通道隔离。仅当特定字段更新时，才会变更组织架构版本号。大部分的字段都从 GetUserInfo 返回。

具体的实现在文件：ConvertToModelPbUser.cpp。

### 降低全量更新比例

另一个优化是降低全量更新比例，监控发现优化前，全量更新的比例大约有9%，比例还是比较高了：

![比例图](../img/比例图.png)

其中，全量更新的原因有以下几种可能性，其中第一个原因是最大的，第二点次之，第三点是一种可能性，使客户端组织架构可以恢复：

![损坏情况](../img/损坏情况.png)

所以后台也着手在降低全量更新的量，做的主要优化是增加隐藏规则的索引缓存，以及通过数据监控，大部门的同步都是需要7天的流水，所以后台目前策略是记录7天的流水，在物理内存限制和流水时间之间找到了平衡。